---
name: "binary"
description: "Bit manipulation primitives."
...
---
primitive_name: "binary_and"
brief_description: "Binary ANDs two vector registers."
parameters:
   - ctype: "typename Vec::register_type"
     name: "a"
     description: "First vector."
   - ctype: "typename Vec::register_type"
     name: "b"
     description: "Second vector."
returns:
   ctype: "typename Vec::register_type"
   description: "Vector containing result of the binary AND."
testing: #optional
   -  test_name: "and_as_compare"
      requires: ["storeu", "loadu"]
      includes: ["<cstddef>"]
      implementation: |
         using T = typename Vec::base_type;
               std::size_t element_count = 1024;
               testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
               bool allOk = true;
               auto reference_data_ptr = test_helper.data_ref();
               auto reference_result_ptr = test_helper.result_ref();
               auto test_data_ptr = test_helper.data_target();
               auto test_result_ptr = test_helper.result_target();
               for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i+=Vec::vector_element_count()) {
                  std::size_t tester_idx = 0;
                  for(size_t j = i; j < i + Vec::vector_element_count(); ++j) {
                     reference_result_ptr[tester_idx++] = reference_data_ptr[j];
                  }
                  auto vec1 = loadu<Vec>( &test_data_ptr[i] );
                  auto vec2 = loadu<Vec>( &test_data_ptr[i] );
                  auto result = binary_and<Vec>( vec1, vec2 );
                  storeu<Vec>( test_result_ptr, result );
                  test_helper.synchronize();
                  allOk &= test_helper.validate();
               }
               return allOk;
definitions:
#INTEL - AVX512
   - target_extension: "avx512"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: ["avx512f"]
     implementation: "return _mm512_and_si512(a, b);"
   - target_extension: "avx512"
     ctype: ["float", "double"]
     lscpu_flags: ["avx512dq"]
     implementation: "return _mm512_and_{{ intrin_tp_full[ctype] }}(a, b);"
   - target_extension: "avx512"
     ctype: ["float", "double"]
     lscpu_flags: ["avx512f"]
     is_native: False
     implementation: "return _mm512_and_si512(_mm512_castsi512_{{ intrin_tp_full[ctype] }}(a) ,_mm512_castsi512_{{ intrin_tp_full[ctype] }}(b));"
#Intel - AVX2
   - target_extension: "avx2"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: ["avx2"]
     implementation: "return _mm256_and_si256(a, b);"
   - target_extension: "avx2"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: ["avx"]
     is_native: False
     implementation: "return _mm256_and_pd(_mm512_castsi256_pd(a),_mm512_castsi256_pd(b));"
   - target_extension: "avx2"
     ctype: ["float", "double"]
     lscpu_flags: ["avx"]
     implementation: "return _mm256_and_{{ intrin_tp_full[ctype] }}(a,b);"
   - target_extension: "sse"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: ["sse2"]
     implementation: "return _mm_and_si128(a, b);"
   - target_extension: "sse"
     ctype: ["float"]
     lscpu_flags: ["sse"]
     implementation: "return _mm_and_ps(a, b);"
   - target_extension: "sse"
     ctype: [ "double" ]
     lscpu_flags: [ "sse2" ]
     implementation: "return _mm_and_pd(a, b);"
   - target_extension: "neon"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: [ 'neon' ]
     implementation: "return vandq_{{ intrin_tp_full[ctype] }}( a, b );"
   - target_extension: "neon"
     ctype: ["float", "double"]
     lscpu_flags: ['neon']
     note: "is it a good idea to support bitmanipulation for floats and doubles?"
     implementation: "return vreinterpretq_{{ intrin_tp_full[ctype] }}_u{{ intrin_tp[ctype][1] }}(vandq_u{{ intrin_tp[ctype][1] }}( vreinterpretq_u{{ intrin_tp[ctype][1] }}_{{ intrin_tp_full[ctype] }}(a),vreinterpretq_u{{ intrin_tp[ctype][1] }}_{{ intrin_tp_full[ctype] }}(b)));"
   - target_extension: "scalar"
     ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: []
     implementation: "return a & b;"
   - target_extension: "scalar"
     ctype: [ "float" ]
     lscpu_flags: []
     implementation: "return (uint32_t) a & (uint32_t)b;"
   - target_extension: "scalar"
     ctype: ["double"]
     lscpu_flags: []
     implementation: "return (uint64_t) a & (uint64_t)b;"
...