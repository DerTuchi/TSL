---
name: "misc"
description: "Miscellaneous primitives."
...
---
primitive_name: 'pack_bits_linear'
brief_description: 'Packs elements from a vector together using a fixed bitwidth.'
detailed_description: |
  Packs elements from a vector together using a fixed bitwidth. The bitwidth
  must be less than the number of bits in the vector's base type.
  The elements are packed together in little-endian order, i.e. the least
  significant bits of the first element are used first.
parameters:
  - ctype: "const typename Vec::register_type"
    name: "data"
    description: "Data vector."
  - ctype: "const unsigned"
    name: "bitwidth"
    description: "Bitwidth of each element."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing packed elements."
definitions:
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    includes: ["<sycl/ext/intel/ac_types/ac_int.hpp>"]
    implementation: |
      using T = typename Vec::base_type;
      using BigIntT = ac_int<Vec::vector_size_b(), std::is_signed_v<T>>;
      BigIntT intermediate_results[Vec::vector_element_count()];
      //BigIntT const all_zero_but_effective_bits{ (1ULL<<bitwidth) - 1 };
      #pragma unroll
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        //intermediate_results[i] = (all_zero_but_effective_bits & BigIntT{data[i]}) << (bitwidth*i);
        intermediate_results[i] = (BigIntT{data[i]}) << (bitwidth*i);
        //BigIntT data;
        //bit_fill<BigIntT>((T [1]){data[i]});
        ////data.set_val<AC_VAL_0>();
      }
      BigIntT tmp_result{0};
      #pragma unroll
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        tmp_result |=  intermediate_results[i];
      }
      typename Vec::register_type result{};
      #pragma unroll
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = tmp_result.template slc<(sizeof(T)*CHAR_BIT)>((unsigned)(i*(sizeof(T)*CHAR_BIT)));
      }
      return result;
...
---
primitive_name: "pack_bits_linear"
functor_name: "pack_bits_linear_merge"
brief_description: ""
detailed_description: |
  Packs elements from two vector registers together using a fixed bitwidth. The bitwidth
  must be less than the number of bits in the vector's base type.
  The elements are packed together in little-endian order, i.e. the least
  significant bits of the first element are used first.
  The 'src' operand is assumed to be packed already. The 'bit_offset' parameter indicates
  the bit offset of the last set bit in the 'src' operand. The 'data' operand is packed
  and merged with the 'src' operand. The 'bitwidth' parameter indicates the bitwidth of
  each element in the 'data' operand.
parameters:
  - ctype: "const typename Vec::register_type"
    name: "src"
    description: "Source register which is used for merging (assumed to be packed already)."
  - ctype: "const unsigned"
    name: "bit_offset"
    description: "Bit offset of the last set bit."
  - ctype: "const typename Vec::register_type"
    name: "data"
    description: "Data vector."
  - ctype: "const unsigned"
    name: "bitwidth"
    description: "Bitwidth of each element."
returns:
  ctype: "std::tuple<typename Vec::register_type, int, typename Vec::register_type>"
  description: "Tuple containing the merged vector, an int indicating whether the data vector had an overflow (-1: false, >=0 new offset) and the overflow."
  # description: "Vector containing packed and merged elements."
definitions:
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    includes: ["<tuple>", "<sycl/ext/intel/ac_types/ac_int.hpp>"]
    implementation: |
      auto packed_data = tsl::pack_bits_linear<Vec>(data, bitwidth);
      //return std::make_tuple(packed_data, -2, data);
      using T = typename Vec::base_type;
      using BigIntT = ac_int<Vec::vector_size_b(), std::is_signed_v<T>>;
      int src_array[Vec::vector_size_B() / sizeof(int)];
      int const * const src_ptr = reinterpret_cast<int const * const>(src.data());
      int packed_data_array[Vec::vector_size_B() / sizeof(int)];
      int const * const packed_data_ptr = reinterpret_cast<int const * const>(packed_data.data());
      #pragma unroll
      for (std::size_t i = 0; i < Vec::vector_size_B() / sizeof(int); ++i) {
        src_array[i] = src_ptr[i];
        packed_data_array[i] = packed_data_ptr[i];
      }
      BigIntT src_int = ac::bit_fill<BigIntT>(src_array, false);
      BigIntT packed_data_int = ac::bit_fill<BigIntT>(packed_data_array, false);
      src_int |= (packed_data_int << bit_offset);
      typename Vec::register_type result{};
      #pragma unroll
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = src_int.template slc<(sizeof(T)*CHAR_BIT)>((unsigned)(i*(sizeof(T)*CHAR_BIT)));
      }
      // check for overflow
      auto new_bitwidth = (bit_offset + bitwidth * Vec::vector_element_count());
      if (new_bitwidth >= Vec::vector_size_b()) {
        new_bitwidth -= Vec::vector_size_b();
        packed_data_int >>= (bitwidth * Vec::vector_element_count() - new_bitwidth);
        typename Vec::register_type overflow_result{};
        #pragma unroll
        for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          overflow_result[i] = packed_data_int.template slc<(sizeof(T)*CHAR_BIT)>((unsigned)(i*(sizeof(T)*CHAR_BIT)));
        }
        return std::make_tuple(result, new_bitwidth, overflow_result);
      }
      return std::make_tuple(result, -1, data);
...
# ---
# primitive_name: "pack_bits_treelike"
# brief_description: "Packs elements from a vector together using a fixed bitwidth."
# detailed_description: |
#   Packs elements from a vector together using a fixed bitwidth. The bitwidth
#   must be less than the number of bits in the vector's base type.
#   The elements are packed together in little-endian order, i.e. the least
#   significant bits of the first element are used first.
# parameters:
#   - ctype: "const typename Vec::register_type"
#     name: "data"
#     description: "Data vector."
#   - ctype: "const unsigned"
#     name: "bitwidth"
#     description: "Bitwidth of each element."
# returns:
#   ctype: "typename Vec::register_type"
#   description: "Vector containing packed elements."
# definitions:
#   - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
#     ctype: ["uint64_t"]
#     lscpu_flags: ["oneAPIfpgaDev"]
#     vector_length_agnostic: True
#     includes: ["<sycl/ext/intel/ac_types/ac_int.hpp>"]
#     implementation: |
#       using T = typename Vec::base_type;
#       typename Vec::register_type result{};
#       #pragma unroll
#       for(int i = 0; i < Vec::vector_element_count(); i+=16) {
#         T add_1_1 = value[ 0] + value[ 1];
#         T add_1_2 = value[ 2] + value[ 3];
#         T add_1_3 = value[ 4] + value[ 5];
#         T add_1_4 = value[ 6] + value[ 7];

#         T add_2_1 = add_1_1 + add_1_2;
#         T add_2_2 = add_1_3 + add_1_4;

#         result += add_2_1 + add_2_2;
#       }
#       return result;
# ...
---
primitive_name: "conflict"
brief_description: "Checks whether all elements are unique in a register."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "data"
    description: "Data vector."
    declaration_attributes: "[[maybe_unused]]"
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the uniqueness check."
definitions:
  #INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t","int32_t", "int64_t"]
    lscpu_flags: ["avx512f", "avx512cd"]
    implementation: "return _mm512_conflict_epi{{ intrin_tp[ctype][1] }}(data);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    implementation: |
       alignas(Vec::vector_alignment())
         std::array<typename Vec::base_type, Vec::vector_element_count()> tmp{};
       alignas(Vec::vector_alignment())
         std::array<typename Vec::base_type, Vec::vector_element_count()> conflicts{};
       _mm512_store_si512(reinterpret_cast<void*>(tmp.data()), data);
       _mm512_store_si512(reinterpret_cast<void*>(conflicts.data()), _mm512_setzero_si512());
       for(unsigned ref = 1; ref < Vec::vector_element_count(); ++ref) {
         for(unsigned cur = 0; cur < ref; ++cur) {
           if(tmp[ref] == tmp[cur]) {
             conflicts[ref] |= (1<<cur);
           }
         }
       }
       return _mm512_load_si512(reinterpret_cast<void const*>(conflicts.data()));
  #Intel - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ["avx2"]
    is_native: False
    implementation: |
      alignas(Vec::vector_alignment())
        std::array<typename Vec::base_type, Vec::vector_element_count()> tmp{};
      alignas(Vec::vector_alignment())
        std::array<typename Vec::base_type, Vec::vector_element_count()> conflicts{};
      _mm256_store_si256(reinterpret_cast<__m256i*>(tmp.data()), data);
      _mm256_store_si256(reinterpret_cast<__m256i*>(conflicts.data()), _mm256_setzero_si256());
      for(unsigned ref = 1; ref < Vec::vector_element_count(); ++ref) {
        for(unsigned cur = 0; cur < ref; ++cur) {
          if(tmp[ref] == tmp[cur]) {
            conflicts[ref] |= (1<<cur);
          }
        }
      }
      return _mm256_load_si256(reinterpret_cast<__m256i const*>(conflicts.data()));
  #Intel - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ["sse2"]
    is_native: False
    implementation: |
      alignas(Vec::vector_alignment())
        std::array<typename Vec::base_type, Vec::vector_element_count()> tmp{};
      alignas(Vec::vector_alignment())
        std::array<typename Vec::base_type, Vec::vector_element_count()> conflicts{};
      _mm_store_si128(reinterpret_cast<__m128i*>(tmp.data()), data);
      _mm_store_si128(reinterpret_cast<__m128i*>(conflicts.data()), _mm_setzero_si128());
      for(unsigned ref = 1; ref < Vec::vector_element_count(); ++ref) {
        for(unsigned cur = 0; cur < ref; ++cur) {
          if(tmp[ref] == tmp[cur]) {
            conflicts[ref] |= (1<<cur);
          }
        }
      }
      return _mm_load_si128(reinterpret_cast<__m128i const*>(conflicts.data()));
  #ARM - NEON
  - target_extension: "neon"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: [ 'neon' ]
    is_native: False
    implementation: |
      alignas(Vec::vector_alignment())
        std::array<typename Vec::base_type, Vec::vector_element_count()> tmp{};
      alignas(Vec::vector_alignment())
        std::array<typename Vec::base_type, Vec::vector_element_count()> conflicts{};
      vst1q_{{ intrin_tp_full[ctype] }}(tmp.data(), data);
      for(unsigned idx = 0; idx < Vec::vector_element_count(); ++idx) {
        conflicts[idx] = 0;
      }
      for(unsigned ref = 1; ref < Vec::vector_element_count(); ++ref) {
        for(unsigned cur = 0; cur < ref; ++cur) {
          if(tmp[ref] == tmp[cur]) {
            conflicts[ref] |= (1<<cur);
          }
        }
      }
      return vld1q_{{ intrin_tp_full[ctype] }}(conflicts.data());
  #SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: []
    implementation: "return 0;"
...
---
primitive_name: "conflict_free"
functor_name: "imask_conflict_free"
brief_description: "Checks whether all elements are unique in a register and returns a mask indicating which elements don't have preceeding conflicts."
parameters:
  - ctype: "const typename Vec::imask_type"
    name: "mask"
    description: "Mask indicating which lanes should be considered for conflict detection. Be aware, that non-valid lanes can still conflict with others."
    declaration_attributes: "[[maybe_unused]]"
  - ctype: "const typename Vec::register_type"
    name: "data"
    description: "Data vector."
    declaration_attributes: "[[maybe_unused]]"
returns:
  ctype: "typename Vec::imask_type"
  description: "integral mask containing result of the uniqueness check."
definitions:
  #INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t","int32_t", "int64_t"]
    lscpu_flags: ["avx512f", "avx512cd"]
    implementation: |
      auto const conflict_reg = _mm512_maskz_conflict_epi{{ intrin_tp[ctype][1] }}(mask, data);
      auto const mask_reg = _mm512_set1_epi{{ intrin_tp[ctype][1] }}(mask);
      auto const cleaned_conflict_reg = _mm512_and_si512(conflict_reg, mask_reg);
      return _mm512_mask_cmpeq_epi{{ intrin_tp[ctype][1] }}_mask(mask, cleaned_conflict_reg, _mm512_setzero_si512());
  - target_extension: "avx512"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    implementation: |
      typename Vec::imask_type result = 0;
      alignas(Vec::vector_alignment())
        std::array<typename Vec::base_type, Vec::vector_element_count()> tmp{};
      _mm512_store_si512(reinterpret_cast<void*>(tmp.data()), data);
      typename Vec::imask_type pos = 2;
      for(unsigned ref = 1; ref < Vec::vector_element_count(); ++ref) {
        if(((mask>>ref)&0b1)==1) {
          for(unsigned cur = 0; cur < ref; ++cur) {
            if(((mask>>cur)&0b1)==1) {
              if(tmp[ref] == tmp[cur]) {
                result |= pos;
                break;
              }
            }
          }
        }
        pos <<= 1;
      }
      return (~result & mask);
  #Intel - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ["avx2"]
    is_native: False
    specialization_comment: "@todo This can be done better using some shuffle instructions cleverly."
    implementation: |
      typename Vec::imask_type result = 0;
      alignas(Vec::vector_alignment())
        std::array<typename Vec::base_type, Vec::vector_element_count()> tmp{};
      _mm256_store_si256(reinterpret_cast<__m256i*>(tmp.data()), data);
      typename Vec::imask_type pos = 2;
      for(unsigned ref = 1; ref < Vec::vector_element_count(); ++ref) {
        if(((mask>>ref)&0b1)==1) {
          for(unsigned cur = 0; cur < ref; ++cur) {
            if(((mask>>cur)&0b1)==1) {
              if(tmp[ref] == tmp[cur]) {
                result |= pos;
                break;
              }
            }
          }
        }
        pos <<= 1;
      }
      return (~result & mask);
  #Intel - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ["sse2"]
    is_native: False
    implementation: |
      typename Vec::imask_type result = 0;
      alignas(Vec::vector_alignment())
        std::array<typename Vec::base_type, Vec::vector_element_count()> tmp{};
      _mm_store_si128(reinterpret_cast<__m128i*>(tmp.data()), data);
      typename Vec::imask_type pos = 2;
      for(unsigned ref = 1; ref < Vec::vector_element_count(); ++ref) {
        if(((mask>>ref)&0b1)==1) {
          for(unsigned cur = 0; cur < ref; ++cur) {
            if(((mask>>cur)&0b1)==1) {
              if(tmp[ref] == tmp[cur]) {
                result |= pos;
                break;
              }
            }
          }
        }
        pos <<= 1;
      }
      return (~result & mask);
  #SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: []
    implementation: "return 1;"
...
---
primitive_name: "blend"
brief_description: "Blends two registers using provided bitmask."
parameters:
  - ctype: "const typename Vec::mask_type"
    name: "control"
    description: "If control[i] == 0, the corresponding value from left register is used, from right otherwise."
  - ctype: "const typename Vec::register_type"
    name: "left"
    description: "Left data."
  - ctype: "const typename Vec::register_type"
    name: "right"
    description: "Right data."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing blended data."
definitions:
  #INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ['avx512f', 'avx512bw']
    implementation: "return _mm512_mask_blend_epi{{ intrin_tp[ctype][1] }}(control, left, right);"
  - target_extension: "avx512"
    ctype: ["uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ['avx512f']
    implementation: "return _mm512_mask_blend_epi{{ intrin_tp[ctype][1] }}(control, left, right);"
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ['avx512f']
    implementation: "return _mm512_mask_blend_{{ intrin_tp_full[ctype] }}(control, left, right);"
  #INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "int32_t", "uint32_t", "int64_t", "uint64_t"]
    lscpu_flags: ['avx2']
    implementation: "return _mm256_or_si256(_mm256_andnot_si256(control, left), _mm256_and_si256(control,right));"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ['avx2']
    #implementation: "return _mm256_or_{{ intrin_tp_full[ctype] }}(_mm256_andnot_{{ intrin_tp_full[ctype] }}(_mm256_castsi256_{{ intrin_tp_full[ctype] }}(control), left), _mm256_and_{{ intrin_tp_full[ctype] }}(_mm256_castsi256_{{
    #intrin_tp_full[ctype] }}(control),right));"
    implementation: "return _mm256_or_{{ intrin_tp_full[ctype] }}(_mm256_andnot_{{ intrin_tp_full[ctype] }}(control, left), _mm256_and_{{ intrin_tp_full[ctype] }}(control,right));"
  #INTEL - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "int32_t", "uint32_t", "int64_t", "uint64_t"]
    lscpu_flags: ['sse2']
    implementation: "return _mm_or_si128(_mm_andnot_si128(control, left), _mm_and_si128(control,right));"
  - target_extension: "sse"
    ctype: ["float", "double"]
    lscpu_flags: ['avx2']
    #implementation: "return _mm_or_{{ intrin_tp_full[ctype] }}(_mm_andnot_{{ intrin_tp_full[ctype] }}(_mm_castsi128_{{ intrin_tp_full[ctype] }}(control), left), _mm_and_{{ intrin_tp_full[ctype] }}(_mm_castsi128_{{ intrin_tp_full[ctype] }}
    #(control),right));"
    implementation: "return _mm_or_{{ intrin_tp_full[ctype] }}(_mm_andnot_{{ intrin_tp_full[ctype] }}(control, left), _mm_and_{{ intrin_tp_full[ctype] }}(control,right));"
...
---
primitive_name: "blend_add"
brief_description: "Blends or add two registers using provided bitmask"
parameters:
  - ctype: "const typename Vec::mask_type"
    name: "control"
  - ctype: "const typename Vec::register_type"
    name: "left"
    description: "Left data."
  - ctype: "const typename Vec::register_type"
    name: "right"
    description: "Right data."
  - ctype: "const typename Vec::register_type"
    name: "adder"
    description: "Adder data."
returns:
  ctype: "typename Vec::register_type"
  descriptions: "result[i] = (control[i]==1)? left[i]  : right[i] + adder[i]"
definitions:
  #INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    implementation: |
      auto const right_added_part = _mm512_add_epi{{ intrin_tp[ctype][1] }}(right, adder);
      return _mm512_mask_blend_epi{{ intrin_tp[ctype][1] }}(control, right_added_part, left);
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ["avx512f", "avx512bw"]
    is_native: False
    implementation: |
      auto const right_added_part = _mm512_add_epi{{ intrin_tp[ctype][1] }}(right, adder);
      return _mm512_mask_blend_epi{{ intrin_tp[ctype][1] }}(control, right_added_part, left);
  #INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx2"]
    is_native: False
    implementation: |
      auto const left_part = _mm256_and_si256(control, left);
      auto const right_added_part = _mm256_andnot_si256(control, _mm256_add_epi{{ intrin_tp[ctype][1] }}(right, adder));
      return _mm256_or_si256(left_part, right_added_part);
...
---
primitive_name: "undefined"
brief_description: "Returns a vector register with undefined data inside."
returns:
  ctype: "typename Vec::register_type"
  description: "SIMD reigster"
definitions:
  #INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_undefined_epi32();"
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_undefined_{{ intrin_tp_full[ctype] }}();"
  #INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_undefined_si256();"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_undefined_{{ intrin_tp_full[ctype] }}();"
  #INTEL - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_undefined_si128();"
  - target_extension: "sse"
    ctype: ["float", "double"]
    lscpu_flags: ["sse", "sse2"]
    implementation: "return _mm_undefined_{{ intrin_tp_full[ctype] }}();"
...
